{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference with Neural Posterior Estimation (NPE)",
   "id": "3d684170c7ac2952"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:53:59.975556Z",
     "start_time": "2025-07-03T11:53:54.729448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pyabc\n",
    "from fitmulticell import model as morpheus_model\n",
    "from fitmulticell.sumstat import SummaryStatistics\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "from sklearn.linear_model import Lasso\n",
    "import seaborn as sns\n",
    "\n",
    "from load_bayesflow_model import load_model, custom_loader, EnsembleTrainer\n",
    "from plotting_routines import plot_posterior_2d\n",
    "from summary_stats import reduce_to_coordinates\n",
    "\n",
    "import tensorflow as tf\n",
    "import bayesflow as bf\n",
    "from bayesflow.simulation import GenerativeModel, Prior, Simulator\n",
    "\n",
    "# get the job array id and number of processors\n",
    "job_array_id = 0 #int(os.environ.get('SLURM_ARRAY_TASK_ID', 0))\n",
    "n_procs = 10 #int(os.environ.get('SLURM_CPUS_PER_TASK', 1))\n",
    "print(job_array_id)\n",
    "on_cluster = False"
   ],
   "id": "10b55f49c4d5c93c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:54:00.058987Z",
     "start_time": "2025-07-03T11:54:00.052357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if on_cluster:\n",
    "    gp = '/home/jarruda_hpc/CellMigration/synth_data_params_bayesflow'\n",
    "else:\n",
    "    gp = os.getcwd()\n",
    "\n",
    "# defining the mapping of parameter inside the model xml file. the dictionary name is for \n",
    "# parameter name, and the value are the mapping values, to get the map value for parameter \n",
    "# check here: https://fitmulticell.readthedocs.io/en/latest/example/minimal.html#Inference-problem-definition\n",
    "\n",
    "par_map = {\n",
    "    'gradient_strength': './CellTypes/CellType/Constant[@symbol=\"gradient_strength\"]',\n",
    "    'move.strength': './CellTypes/CellType/Constant[@symbol=\"move.strength\"]',\n",
    "    'move.duration.mean': './CellTypes/CellType/Constant[@symbol=\"move.duration.mean\"]',\n",
    "    'cell_nodes_real': './Global/Constant[@symbol=\"cell_nodes_real\"]',\n",
    "}\n",
    "\n",
    "model_path = gp + \"/cell_movement_v24.xml\"  # time step is 30sec, move.dir completely normalized, init move.dir rand in all directions\n",
    "# defining the summary statistics function\n",
    "max_sequence_length = 120\n",
    "min_sequence_length = 0\n",
    "only_longest_traj_per_cell = True  # mainly to keep the data batchable\n",
    "sumstat = SummaryStatistics(sum_stat_calculator=partial(reduce_to_coordinates,\n",
    "                                                        minimal_length=min_sequence_length,\n",
    "                                                        maximal_length=max_sequence_length,\n",
    "                                                        only_longest_traj_per_cell=only_longest_traj_per_cell))                    \n",
    "\n",
    "if on_cluster:\n",
    "    # define the model object\n",
    "    model = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        executable=\"ulimit -s unlimited; /home/jarruda_hpc/CellMigration/morpheus-2.3.7\",\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)\n",
    "\n",
    "    # todo: remember also change tiff path in model.xml!\n",
    "else:\n",
    "    # define the model object\n",
    "    model = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)\n",
    "\n",
    "\n",
    "# parameter values used to generate the synthetic data\n",
    "obs_pars = {\n",
    "    'gradient_strength': 100.,  # strength of the gradient of chemotaxis (energy potential)\n",
    "    'move.strength': 10.,  # strength of directed motion (energy potential)\n",
    "    'move.duration.mean': 0.1,  # mean of exponential distribution (seconds)\n",
    "    'cell_nodes_real': 50.,  # area of the cell  (\\mu m^2)\n",
    "}\n",
    "\n",
    "obs_pars_log = {key: np.log10(val) for key, val in obs_pars.items()}\n",
    "limits = {'gradient_strength': (1, 10000), #(10 ** 4, 10 ** 8),\n",
    "          'move.strength': (1, 100),\n",
    "          'move.duration.mean': (1e-4, 30), #(math.log10((10 ** -2) * 30), math.log10((10 ** 4))), # smallest time step in simulation 5\n",
    "          'cell_nodes_real': (1, 300)}\n",
    "limits_log = {key: (np.log10(val[0]), np.log10(val[1])) for key, val in limits.items()}\n",
    "\n",
    "\n",
    "prior = pyabc.Distribution(**{key: pyabc.RV(\"uniform\", loc=lb, scale=ub-lb)\n",
    "                              for key, (lb, ub) in limits_log.items()})\n",
    "param_names = ['$m_{\\\\text{dir}}$', '$m_{\\\\text{rand}}$', '$w$', '$a$']\n",
    "log_param_names = ['$\\log_{10}(m_{\\\\text{dir}})$', '$\\log_{10}(m_{\\\\text{rand}})$', '$\\log_{10}(w)$', '$\\log_{10}(a)$']\n",
    "print(obs_pars)"
   ],
   "id": "74390dfb0e802a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_strength': 100.0, 'move.strength': 10.0, 'move.duration.mean': 0.1, 'cell_nodes_real': 50.0}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:54:00.073539Z",
     "start_time": "2025-07-03T11:54:00.068602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prior_fun(batch_size: int) -> np.ndarray:\n",
    "    samples = []\n",
    "    for _ in range(batch_size):\n",
    "        samples.append(list(prior.rvs().values()))\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def generate_population_data(param_batch: np.ndarray, cells_in_population: int, max_length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate population data\n",
    "    :param param_batch:  batch of parameters\n",
    "    :param cells_in_population:  number of cells in a population (50)\n",
    "    :param max_length:  maximum length of the sequence\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_batch = []\n",
    "    for params in param_batch:\n",
    "        params_dict = {key: p for key, p in zip(obs_pars.keys(), params)}\n",
    "        sim = model.sample(params_dict)\n",
    "        data_batch.append(sim)  # generates a cell population in one experiment\n",
    "\n",
    "    data_batch_transformed = np.ones((param_batch.shape[0], cells_in_population, max_length, 3)) * np.nan\n",
    "    # each cell is of different length, each with x and y coordinates, make a tensor out of it\n",
    "    n_cells_not_visible = 0\n",
    "    for p_id, population_sim in enumerate(data_batch):\n",
    "        if len(population_sim) == 0:\n",
    "            # no cells were visible in the simulation\n",
    "            n_cells_not_visible += 1\n",
    "            continue\n",
    "        for c_id, cell_sim in enumerate(population_sim):\n",
    "            # pre-pad the data with zeros, but first write zeros as nans to compute the mean and std\n",
    "            data_batch_transformed[p_id, c_id, -len(cell_sim['x']):, 0] = cell_sim['x']\n",
    "            data_batch_transformed[p_id, c_id, -len(cell_sim['y']):, 1] = cell_sim['y']\n",
    "            data_batch_transformed[p_id, c_id, -len(cell_sim['t']):, 2] = cell_sim['t']\n",
    "\n",
    "    if n_cells_not_visible > 0:\n",
    "        print(f'Simulation with no cells visible: {n_cells_not_visible}/{len(data_batch)}')\n",
    "    return data_batch_transformed"
   ],
   "id": "c606f75e3a4c0257",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:54:00.090796Z",
     "start_time": "2025-07-03T11:54:00.086943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "presimulate = False\n",
    "presimulation_path = 'presimulations'\n",
    "n_val_data = 100\n",
    "cells_in_population = 143\n",
    "n_params = len(obs_pars)\n",
    "batch_size = 32\n",
    "iterations_per_epoch = 100\n",
    "# 1000 batches to be generated, 10 epochs until the batch is used again\n",
    "epochs = 500\n",
    "\n",
    "# check if gpu is available\n",
    "print('gpu:', tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "bayesflow_prior = Prior(batch_prior_fun=prior_fun, param_names=param_names)\n",
    "bayes_simulator = Simulator(batch_simulator_fun=partial(generate_population_data,\n",
    "                                                        cells_in_population=cells_in_population,\n",
    "                                                        max_length=max_sequence_length))\n",
    "generative_model = GenerativeModel(prior=bayesflow_prior, simulator=bayes_simulator,\n",
    "                                   skip_test=True,  # once is enough, simulation takes time\n",
    "                                   name=\"Normalizing Flow Generative Model\")"
   ],
   "id": "cecd0d3e2713e759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: []\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:54:00.176412Z",
     "start_time": "2025-07-03T11:54:00.174009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if presimulate:\n",
    "    print('presimulating')\n",
    "    from time import sleep\n",
    "    sleep(job_array_id)\n",
    "\n",
    "    # we create on batch per job and save it in a folder\n",
    "    epoch_id = job_array_id // iterations_per_epoch\n",
    "    generative_model.presimulate_and_save(\n",
    "        batch_size=batch_size,\n",
    "        folder_path=presimulation_path+f'/epoch_{epoch_id}',\n",
    "        iterations_per_epoch=1,\n",
    "        epochs=1,\n",
    "        extend_from=job_array_id,\n",
    "        disable_user_input=True\n",
    "    )\n",
    "    print('Done!')"
   ],
   "id": "958a416f9ac30668",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:59:31.958614Z",
     "start_time": "2025-07-03T11:59:29.035295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(os.path.join(gp, 'validation_data.pickle')):\n",
    "    with open(os.path.join(gp, 'validation_data.pickle'), 'rb') as f:\n",
    "        valid_data = pickle.load(f)\n",
    "else:\n",
    "    print('Generating validation data')\n",
    "    valid_data = generative_model(n_val_data)\n",
    "    # save the data\n",
    "    with open(os.path.join(gp, 'validation_data.pickle'), 'wb') as f:\n",
    "        pickle.dump(valid_data, f)\n",
    "\n",
    "x_mean = np.nanmean(valid_data['sim_data'], axis=(0, 1, 2))\n",
    "x_std = np.nanstd(valid_data['sim_data'], axis=(0, 1, 2))\n",
    "p_mean = np.mean(valid_data['prior_draws'], axis=0)\n",
    "p_std = np.std(valid_data['prior_draws'], axis=0)\n",
    "print('Mean and std of data:', x_mean, x_std)\n",
    "print('Mean and std of parameters:', p_mean, p_std)"
   ],
   "id": "df1829ce49462436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenerating validation data\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m     valid_data \u001B[38;5;241m=\u001B[39m \u001B[43mgenerative_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_val_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# save the data\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(gp, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_data.pickle\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/bayesflow/simulation.py:773\u001B[0m, in \u001B[0;36mGenerativeModel.__call__\u001B[0;34m(self, batch_size, **kwargs)\u001B[0m\n\u001B[1;32m    771\u001B[0m \u001B[38;5;66;03m# Forward inference\u001B[39;00m\n\u001B[1;32m    772\u001B[0m prior_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprior(batch_size, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprior_args\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\n\u001B[0;32m--> 773\u001B[0m sim_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprior_out\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprior_draws\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msim_args\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;66;03m# Prepare and fill placeholder dict\u001B[39;00m\n\u001B[1;32m    776\u001B[0m out_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    777\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprior_non_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]: prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[1;32m    778\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprior_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]: prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    782\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]: sim_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[1;32m    783\u001B[0m }\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/bayesflow/simulation.py:597\u001B[0m, in \u001B[0;36mSimulator.__call__\u001B[0;34m(self, params, *args, **kwargs)\u001B[0m\n\u001B[1;32m    594\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m context_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_batched:\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_simulate_batched\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_simulate_non_batched(params, out_dict, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/bayesflow/simulation.py:608\u001B[0m, in \u001B[0;36mSimulator._simulate_batched\u001B[0;34m(self, params, out_dict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;66;03m# No context type\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    605\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    606\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    607\u001B[0m ):\n\u001B[0;32m--> 608\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Only batchable context\u001B[39;00m\n\u001B[1;32m    611\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m out_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[3], line 19\u001B[0m, in \u001B[0;36mgenerate_population_data\u001B[0;34m(param_batch, cells_in_population, max_length)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m params \u001B[38;5;129;01min\u001B[39;00m param_batch:\n\u001B[1;32m     18\u001B[0m     params_dict \u001B[38;5;241m=\u001B[39m {key: p \u001B[38;5;28;01mfor\u001B[39;00m key, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(obs_pars\u001B[38;5;241m.\u001B[39mkeys(), params)}\n\u001B[0;32m---> 19\u001B[0m     sim \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     data_batch\u001B[38;5;241m.\u001B[39mappend(sim)  \u001B[38;5;66;03m# generates a cell population in one experiment\u001B[39;00m\n\u001B[1;32m     22\u001B[0m data_batch_transformed \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones((param_batch\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], cells_in_population, max_length, \u001B[38;5;241m3\u001B[39m)) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mnan\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/pyabc/external/base.py:246\u001B[0m, in \u001B[0;36mExternalModel.sample\u001B[0;34m(self, pars)\u001B[0m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msample\u001B[39m(\u001B[38;5;28mself\u001B[39m, pars):\n\u001B[0;32m--> 246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpars\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/fitmulticell/model/base.py:173\u001B[0m, in \u001B[0;36mMorpheusModel.__call__\u001B[0;34m(self, pars)\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meh\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# call the model\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m status \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;66;03m# check whether simulation timed out\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m status[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturncode\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m TIMEOUT:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;66;03m# remove simulation output\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/site-packages/pyabc/external/base.py:143\u001B[0m, in \u001B[0;36mExternalHandler.run\u001B[0;34m(self, args, cmd, loc)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cmd \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 143\u001B[0m         status \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m            \u001B[49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# noqa: S602\u001B[39;49;00m\n\u001B[1;32m    146\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstderr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m         executable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_executable(loc)\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/subprocess.py:505\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Popen(\u001B[38;5;241m*\u001B[39mpopenargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 505\u001B[0m         stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[43mprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommunicate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TimeoutExpired \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    507\u001B[0m         process\u001B[38;5;241m.\u001B[39mkill()\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/subprocess.py:1146\u001B[0m, in \u001B[0;36mPopen.communicate\u001B[0;34m(self, input, timeout)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         stderr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1145\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1146\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/subprocess.py:1209\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1207\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m _time() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1209\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1210\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1211\u001B[0m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[1;32m   1212\u001B[0m     \u001B[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001B[39;00m\n\u001B[1;32m   1213\u001B[0m     \u001B[38;5;66;03m# exit under the common assumption that it also received the ^C\u001B[39;00m\n\u001B[1;32m   1214\u001B[0m     \u001B[38;5;66;03m# generated SIGINT and will exit rapidly.\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/subprocess.py:1959\u001B[0m, in \u001B[0;36mPopen._wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1958\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# Another thread waited.\u001B[39;00m\n\u001B[0;32m-> 1959\u001B[0m (pid, sts) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001B[39;00m\n\u001B[1;32m   1961\u001B[0m \u001B[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001B[39;00m\n\u001B[1;32m   1962\u001B[0m \u001B[38;5;66;03m# http://bugs.python.org/issue14396.\u001B[39;00m\n\u001B[1;32m   1963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pid \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpid:\n",
      "File \u001B[0;32m~/miniconda/envs/CellMigration/lib/python3.10/subprocess.py:1917\u001B[0m, in \u001B[0;36mPopen._try_wait\u001B[0;34m(self, wait_flags)\u001B[0m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001B[39;00m\n\u001B[1;32m   1916\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1917\u001B[0m     (pid, sts) \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitpid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwait_flags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1918\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mChildProcessError\u001B[39;00m:\n\u001B[1;32m   1919\u001B[0m     \u001B[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001B[39;00m\n\u001B[1;32m   1920\u001B[0m     \u001B[38;5;66;03m# for child processes has otherwise been disabled for our\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m     \u001B[38;5;66;03m# process.  This child is dead, we can't get the status.\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m     pid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpid\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:59:33.762768Z",
     "start_time": "2025-07-03T11:59:33.732966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = 2  # best: 2, ensemble: 3, only summary: 10\n",
    "trainer = load_model(\n",
    "    model_id=model_id,\n",
    "    x_mean=x_mean,\n",
    "    x_std=x_std,\n",
    "    p_mean=p_mean,\n",
    "    p_std=p_std,\n",
    "    generative_model=generative_model\n",
    ")"
   ],
   "id": "b81539411969d014",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m  \u001B[38;5;66;03m# best: 2, ensemble: 3, only summary: 10\u001B[39;00m\n\u001B[1;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m load_model(\n\u001B[1;32m      3\u001B[0m     model_id\u001B[38;5;241m=\u001B[39mmodel_id,\n\u001B[0;32m----> 4\u001B[0m     x_mean\u001B[38;5;241m=\u001B[39m\u001B[43mx_mean\u001B[49m,\n\u001B[1;32m      5\u001B[0m     x_std\u001B[38;5;241m=\u001B[39mx_std,\n\u001B[1;32m      6\u001B[0m     p_mean\u001B[38;5;241m=\u001B[39mp_mean,\n\u001B[1;32m      7\u001B[0m     p_std\u001B[38;5;241m=\u001B[39mp_std,\n\u001B[1;32m      8\u001B[0m     generative_model\u001B[38;5;241m=\u001B[39mgenerative_model\n\u001B[1;32m      9\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_mean' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check if the model is already trained\n",
    "if not os.path.exists(trainer.checkpoint_path) and not isinstance(trainer, EnsembleTrainer):\n",
    "    trainer._setup_optimizer(\n",
    "        optimizer=None,\n",
    "        epochs=epochs,\n",
    "        iterations_per_epoch=iterations_per_epoch\n",
    "    )\n",
    "\n",
    "    history = trainer.train_from_presimulation(\n",
    "        presimulation_path=presimulation_path,\n",
    "        optimizer=trainer.optimizer,\n",
    "        max_epochs=epochs,\n",
    "        early_stopping=True,\n",
    "        early_stopping_args={'patience': 17 - 2},\n",
    "        custom_loader=custom_loader,\n",
    "        validation_sims=valid_data\n",
    "    )\n",
    "    print('Training done!')\n",
    "else:\n",
    "    history = trainer.loss_history.get_plottable()\n",
    "\n",
    "bf.diagnostics.plot_losses(history['train_losses'], history['val_losses'], fig_size=(10, 6))\n",
    "print('Final validation loss:', np.min(history['val_losses']))"
   ],
   "id": "a7c0835963566e42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Diagnostic plots",
   "id": "c72ff040811c2643"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rmse(true_params, ps):\n",
    "    return np.median(np.sqrt(np.mean((true_params[:, np.newaxis] - ps) ** 2, axis=1)), axis=0)"
   ],
   "id": "321a71528c389c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "valid_data_config = trainer.configurator(valid_data)",
   "id": "4f6939fee4bd108a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_samples = trainer.amortizer.sample(valid_data_config, n_samples=1000)\n",
    "posterior_samples = posterior_samples * p_std + p_mean\n",
    "if isinstance(valid_data_config, list):  # for ensemble\n",
    "    prior_draws = valid_data_config[0][\"parameters\"] * p_std + p_mean\n",
    "else:\n",
    "    prior_draws = valid_data_config[\"parameters\"] * p_std + p_mean"
   ],
   "id": "f6ad80516d7191c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('RMSE:', rmse(prior_draws, posterior_samples))\n",
    "print('RMSE average:', np.mean(rmse(prior_draws, posterior_samples)))"
   ],
   "id": "ab323cd63f7b0655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bf.diagnostics.plot_sbc_ecdf(posterior_samples, prior_draws, difference=True, param_names=log_param_names);\n",
    "plt.savefig(f'{trainer.checkpoint_path}/sbc_ecdf.pdf')"
   ],
   "id": "bf28748d802ce799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bf.diagnostics.plot_recovery(posterior_samples, prior_draws, #uncertainty_agg=None,\n",
    "                             param_names=log_param_names);\n",
    "plt.savefig(f'{trainer.checkpoint_path}/recovery.pdf')"
   ],
   "id": "a8a443ecb123ad2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bf.diagnostics.plot_z_score_contraction(posterior_samples, prior_draws, param_names=log_param_names);",
   "id": "69522e989ab5747d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# regress summary statistics to parameters to identify the most important latent dimensions\n",
    "if isinstance(trainer, EnsembleTrainer):\n",
    "    assert False  # changes the valid_data_config to a list\n",
    "    summary_output = trainer.amortizer.summary_net(valid_data_config)\n",
    "    valid_data_config = valid_data_config[0]\n",
    "else:\n",
    "    summary_output = trainer.amortizer.summary_net(valid_data_config['summary_conditions'])\n",
    "\n",
    "if job_array_id == 10:\n",
    "    summary_output = summary_output * p_std + p_mean\n",
    "    fig = bf.diagnostics.plot_recovery(summary_output[:, np.newaxis], prior_draws, param_names=log_param_names)\n",
    "    plt.savefig(f'{trainer.checkpoint_path}/summary_space_recovery.pdf')\n",
    "\n",
    "# perform a regression of each parameter to the summary statistics\n",
    "regressors = []\n",
    "for i in range(valid_data_config['parameters'].shape[1]):\n",
    "    reg = Lasso(alpha=0.1).fit(summary_output, valid_data_config['parameters'][:, i])\n",
    "    regressors.append(reg.coef_)\n",
    "\n",
    "# Convert list of coefficients to a NumPy array for visualization\n",
    "coeff_matrix = np.array(regressors).T\n",
    "\n",
    "# Identify the parameter for which each latent dimension is most important\n",
    "dominant_param = np.argmax(np.abs(coeff_matrix), axis=1)\n",
    "\n",
    "# Group latent dimensions based on the dominant parameter\n",
    "grouped_indices = []\n",
    "for param_idx in range(n_params):\n",
    "    group = [i for i in range(summary_output.shape[1]) if dominant_param[i] == param_idx]\n",
    "    grouped_indices.extend(group)\n",
    "\n",
    "# Reorder the coefficient matrix based on the grouped indices\n",
    "grouped_coeff_matrix = coeff_matrix[grouped_indices, :]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(\n",
    "    np.abs(grouped_coeff_matrix).T,\n",
    "    annot=True,\n",
    "    cmap=sns.color_palette(\"flare\", as_cmap=True),\n",
    "    yticklabels=log_param_names,\n",
    "    xticklabels=[f\"Dim {i}\" for i in range(summary_output.shape[1])],\n",
    "    cbar_kws={'label': 'Absolute Coefficient Value'}\n",
    ")\n",
    "#plt.title(\"Regression Coefficients: Latent Dimensions vs Model Parameters\")\n",
    "plt.ylabel(\"Model Parameters\")\n",
    "plt.xlabel(\"Latent Dimensions\")\n",
    "plt.savefig(f'{trainer.checkpoint_path}/summary_space_regression_coefficients.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# apply a UMAP to the summary statistics\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1)\n",
    "embedding = reducer.fit_transform(summary_output)\n",
    "\n",
    "fix, ax = plt.subplots(1, n_params, sharey=True, sharex=True, figsize=(12, 3))\n",
    "for i in range(n_params):\n",
    "    # color code base on size of parameter\n",
    "    colors = valid_data_config['parameters'][:, i]\n",
    "    # min max scaling\n",
    "    colors = (colors - np.min(colors)) / (np.max(colors) - np.min(colors))\n",
    "    # map to colormap\n",
    "    colormap = plt.get_cmap('flare')\n",
    "    colors = colormap(colors)\n",
    "\n",
    "    ax[i].scatter(\n",
    "        embedding[:, 0],\n",
    "        embedding[:, 1],\n",
    "        # color code base on size of parameter\n",
    "        c=colors,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax[i].set_title(f\"{log_param_names[i]}\")\n",
    "\n",
    "# add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=colormap, norm=plt.Normalize(vmin=np.min(colors), vmax=np.max(colors)))\n",
    "sm._A = []\n",
    "plt.colorbar(sm, ax=ax, label='Normalized Parameter Value')\n",
    "plt.savefig(f'{trainer.checkpoint_path}/summary_space_umap.pdf')\n",
    "plt.show()"
   ],
   "id": "681603b5f2e87a03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test on synthetic data\n",
    "\n",
    "Here we use the best model."
   ],
   "id": "26f7a6d31b5bf000"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T11:59:56.840939Z",
     "start_time": "2025-07-03T11:59:40.035105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simulate test data\n",
    "error_rmse = []\n",
    "for test_id in [0, 1, 2]:\n",
    "    print(test_id)\n",
    "    np.random.seed(42+test_id)\n",
    "    test_params = np.array(list(prior.rvs().values()))\n",
    "    if not os.path.exists(os.path.join(gp, f'test_sim_{test_id}.npy')):\n",
    "        test_sim_full = bayes_simulator(test_params[np.newaxis])\n",
    "        test_sim = test_sim_full['sim_data']\n",
    "        np.save(os.path.join(gp, f'test_sim_{test_id}.npy'), test_sim)\n",
    "    else:\n",
    "        test_sim = np.load(os.path.join(gp, f'test_sim_{test_id}.npy'))\n",
    "        test_sim_full = {'sim_data': test_sim}\n",
    "    continue\n",
    "\n",
    "    test_posterior_samples = trainer.amortizer.sample(trainer.configurator(test_sim_full), n_samples=1000)\n",
    "    test_posterior_samples = test_posterior_samples * p_std + p_mean\n",
    "    test_posterior_samples_median = np.median(test_posterior_samples, axis=0)\n",
    "    # compute the log posterior of the test data\n",
    "    input_dict = {\n",
    "        'sim_data': np.repeat(test_sim, repeats=100, axis=0),\n",
    "        'parameters': test_posterior_samples\n",
    "    }\n",
    "\n",
    "    # save posterior samples to load for abc comparison (only for the best model)\n",
    "    #np.save(f'abc_results_{test_id}/posterior_samples_npe.npy', test_posterior_samples)\n",
    "\n",
    "    fig = plot_posterior_2d(posterior_draws=test_posterior_samples,\n",
    "                        prior_draws=prior_draws[:test_posterior_samples.shape[0]],\n",
    "                        param_names=log_param_names,\n",
    "                        true_params=test_params)\n",
    "    plt.show()\n",
    "\n",
    "    error_rmse.append(rmse(test_params[np.newaxis], test_posterior_samples[np.newaxis]))\n",
    "print('RMSE of the posterior samples:', error_rmse)\n",
    "print('Mean RMSE:', np.mean(error_rmse))"
   ],
   "id": "aaf9d11a06bc442f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "RMSE of the posterior samples: []\n",
      "Mean RMSE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas.arruda/miniconda/envs/CellMigration/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/jonas.arruda/miniconda/envs/CellMigration/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Real Data",
   "id": "dc88096666755040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from load_data import load_real_data\n",
    "\n",
    "wasserstein_distance_dict = {0: np.nan, 1: np.nan}\n",
    "samples_dict = {0: np.nan, 1: np.nan}\n",
    "prior_draws = prior_fun(1000)"
   ],
   "id": "88f5e4f6b323ebcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "real_data_id = [0, 1][1]\n",
    "_, real_data_full = load_real_data(data_id=real_data_id,\n",
    "                                   max_sequence_length=max_sequence_length,\n",
    "                                   cells_in_population=cells_in_population,\n",
    "                                   plot_data=True)\n",
    "print(real_data_full.shape)"
   ],
   "id": "748dffc6b156ef8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# make sure that the sub-selected data size is well mixed based on track lengths\n",
    "# import pandas as pd\n",
    "\n",
    "# track_length = []\n",
    "# for cell in real_data_full:\n",
    "#     new_track_length = max_sequence_length-np.isnan(cell[:, 0]).sum()\n",
    "#     track_length.append(new_track_length)\n",
    "# track_length = np.array(track_length)\n",
    "\n",
    "# # Convert to DataFrame for handling\n",
    "# data = pd.DataFrame({'track_length': track_length, 'id': np.arange(len(track_length))})\n",
    "#\n",
    "# # Define number of bins\n",
    "# num_bins = 10  # Adjust for resolution\n",
    "# data['bin'] = pd.cut(data['track_length'], bins=num_bins)\n",
    "#\n",
    "# # Sample an equal number of points from each bin\n",
    "# sampled_data = data.groupby('bin').apply(lambda x: x.sample(min(len(x), 5))).reset_index(drop=True)\n",
    "# real_data_50 = real_data_full[sampled_data['id']]"
   ],
   "id": "52a039b01673630d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zelldichte macht was aus\n",
    "\n",
    "Wo wollen Zellen hin? welche parameter beeinflussen das ganze? Zelldichte?\n",
    "\n",
    "1,5mm\n",
    "\n",
    "1 (nicht so gut, extrema)\n",
    "739.79x279.74  microns\n",
    "20231x768 pixel\n",
    "\n",
    "\n",
    "2 (wesentlich mehr der Wahrheit)\n",
    "882.94x287.03 microns\n",
    "2424x788 pixel\n"
   ],
   "id": "3212d01370d344d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# batch the real data\n",
    "real_posterior_samples = trainer.amortizer.sample(trainer.configurator({'sim_data': real_data_full[np.newaxis]}),\n",
    "                                          n_samples=prior_draws.shape[0])\n",
    "real_posterior_samples = real_posterior_samples * p_std + p_mean\n",
    "\n",
    "if isinstance(trainer, EnsembleTrainer):\n",
    "    np.save(f'abc_results_real/posterior_samples_npe_ensemble.npy', real_posterior_samples)\n",
    "else:\n",
    "    np.save(f'abc_results_real/posterior_samples_npe.npy', real_posterior_samples)\n",
    "samples_dict[real_data_id] = real_posterior_samples"
   ],
   "id": "17248751d4533848",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plot_posterior_2d(posterior_draws=real_posterior_samples,\n",
    "                        prior_draws=prior_draws[:real_posterior_samples.shape[0]],\n",
    "                        param_names=log_param_names)\n",
    "plt.savefig(f'{trainer.checkpoint_path}/full_posterior.png')\n",
    "plt.show()"
   ],
   "id": "aeefa13b15ae4ce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if trainer.amortizer.summary_loss is not None:\n",
    "    from matplotlib.cm import viridis\n",
    "    real_data_config = trainer.configurator({'sim_data': real_data_full[np.newaxis]})\n",
    "    summary_statistics = trainer.amortizer.summary_net(valid_data_config['summary_conditions'])\n",
    "    summary_statistics_obs = trainer.amortizer.summary_net(real_data_config['summary_conditions'])\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    colors = viridis(np.linspace(0.1, 0.9, 2))\n",
    "    ax.scatter(\n",
    "        summary_statistics_obs[:, 0], summary_statistics_obs[:, 1], color=colors[0], label=r\"Observed: $h_{\\psi}(x_{obs})$\"\n",
    "    )\n",
    "    ax.scatter(summary_statistics[:, 0], summary_statistics[:, 1], color=colors[1], label=r\"Well-specified: $h_{\\psi}(x)$\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.2)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    \n",
    "    #fig.savefig(f'abc_results_real/Real_{real_data_id} Summary Latent Space.pdf', bbox_inches='tight')\n",
    "    \n",
    "    MMD_sampling_distribution, MMD_observed = trainer.mmd_hypothesis_test(\n",
    "        observed_data=real_data_config, \n",
    "        reference_data=valid_data_config,  # if not provided, will use the generative model\n",
    "        num_null_samples=500,\n",
    "        bootstrap=True  # if True, use the reference data as null samples\n",
    "    )\n",
    "    fig = bf.diagnostics.plot_mmd_hypothesis_test(MMD_sampling_distribution, MMD_observed)\n",
    "    #fig.savefig(f'abc_results_real/Real_{real_data_id} MMD.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "d79424027ea8180a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Different Number of Cells in Experiment",
   "id": "1d4036aaff03efd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import linregress\n",
    "from scipy.stats import median_abs_deviation"
   ],
   "id": "80307fddc94faeb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# batch the real data\n",
    "n_cell_in_batch = np.arange(1, len(real_data_full))\n",
    "stats_n_cells = {}\n",
    "np.random.seed(0)\n",
    "\n",
    "real_posterior_samples_partial = []\n",
    "real_posterior_samples_artificial = []\n",
    "for n_cells in tqdm(n_cell_in_batch):\n",
    "    n_rand_index = np.random.choice(len(real_data_full), size=n_cells, replace=False)\n",
    "    partial_data = real_data_full[n_rand_index]\n",
    "\n",
    "    real_posterior_samples = trainer.amortizer.sample(trainer.configurator({'sim_data': partial_data[np.newaxis]}),\n",
    "                                                      n_samples=100)\n",
    "    real_posterior_samples = real_posterior_samples * p_std + p_mean\n",
    "    real_posterior_samples_partial.append(real_posterior_samples)\n",
    "\n",
    "real_posterior_samples_partial = np.stack(real_posterior_samples_partial)"
   ],
   "id": "2c4b9f4d313543e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "real_posterior_samples_partial_median = np.median(real_posterior_samples_partial, axis=1)\n",
    "real_posterior_samples_partial_std = median_abs_deviation(real_posterior_samples_partial, axis=1)"
   ],
   "id": "b0e3b2b8aa6196c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 4, sharex='row', sharey='col', figsize=(12, 4), tight_layout=True)\n",
    "\n",
    "for i, p_name in enumerate(log_param_names):\n",
    "    reg = linregress(n_cell_in_batch, real_posterior_samples_partial_median[:, i])\n",
    "\n",
    "    ax[i].errorbar(n_cell_in_batch,  real_posterior_samples_partial_median[:, i],\n",
    "                  yerr=real_posterior_samples_partial_std[:, i],\n",
    "                  fmt='o',\n",
    "                  alpha=0.5, label='Estimate (median $\\pm$ absolute deviation)' if i == 0 else None)\n",
    "\n",
    "    reg = linregress(n_cell_in_batch, real_posterior_samples_partial_median[:, i])\n",
    "    #if reg.pvalue < 0.01:\n",
    "    ax[i].plot(n_cell_in_batch, reg.slope*n_cell_in_batch + reg.intercept,\n",
    "                     color='black', label=f'Regression Line' if i == 1 else None,\n",
    "                   zorder=4)\n",
    "\n",
    "\n",
    "    ax[i].set_title(f\"Correlation {reg.rvalue:.4f}\\n(p-value: {reg.pvalue:.4f})\")\n",
    "    ax[i].set_xlabel('Number of Cells')\n",
    "    ax[i].set_ylabel(f'Median of {log_param_names[i]}')\n",
    "    ax[i].set_ylim(limits_log[list(limits_log.keys())[i]])\n",
    "\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.1))\n",
    "plt.savefig(f'abc_results_real/real_ncells_vs_parameter_median.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "b09bb5e7f54affc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "88d703598d0f0e1a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
