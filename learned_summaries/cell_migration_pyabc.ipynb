{
 "cells": [
  {
   "cell_type": "code",
   "id": "ad524a02726e5c40",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyabc\n",
    "#from pyabc.sampler import RedisEvalParallelSampler\n",
    "import scipy.stats as stats\n",
    "from fitmulticell import model as morpheus_model\n",
    "from fitmulticell.sumstat import SummaryStatistics\n",
    "\n",
    "from load_bayesflow_model import load_model\n",
    "from plotting_routines import plot_compare_summary_stats, plot_trajectory, \\\n",
    "    plot_autocorrelation, sampling_parameter_cis, plot_posterior_2d, plot_sumstats_distance_hist\n",
    "from summary_stats import reduced_coordinates_to_sumstat, reduce_to_coordinates, \\\n",
    "    compute_mean_summary_stats, compute_MSD_lags"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# get the job array id and number of processors\n",
    "job_array_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0))\n",
    "n_procs = int(os.environ.get('SLURM_CPUS_PER_TASK', 1))\n",
    "print(job_array_id)\n",
    "on_cluster = False\n",
    "population_size = 1000\n",
    "load_synthetic_data = False\n",
    "\n",
    "if on_cluster:\n",
    "    parser = argparse.ArgumentParser(description='Parse necessary arguments')\n",
    "    parser.add_argument('-pt', '--port', type=str, default=\"50004\",\n",
    "                        help='Which port should be use?')\n",
    "    parser.add_argument('-ip', '--ip', type=str,\n",
    "                        help='Dynamically passed - BW: Login Node 3')\n",
    "    args = parser.parse_args()"
   ],
   "id": "b3292da9556a2a68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if on_cluster:\n",
    "    gp = '/home/jarruda_hpc/CellMigration/synth_data_params_bayesflow'\n",
    "else:\n",
    "    gp = os.getcwd()\n",
    "\n",
    "par_map = {\n",
    "    'gradient_strength': './CellTypes/CellType/Constant[@symbol=\"gradient_strength\"]',\n",
    "    'move.strength': './CellTypes/CellType/Constant[@symbol=\"move.strength\"]',\n",
    "    'move.duration.mean': './CellTypes/CellType/Constant[@symbol=\"move.duration.mean\"]',\n",
    "    'cell_nodes_real': './Global/Constant[@symbol=\"cell_nodes_real\"]',\n",
    "}\n",
    "\n",
    "model_path = gp + \"/cell_movement_v24.xml\"  # time step is 30sec\n",
    "#model_path = gp + \"/cell_movement_v24-no-pillars.xml\"  # for simulation without pillars\n",
    "#model_path = gp + \"/cell_movement_v24-no-chemokine.xml\"  # for simulation without chemokine\n",
    "#model_path = gp + \"/cell_movement_v24-no-chemokine-no-pillars.xml\"  # for simulation without chemokine and without pillars\n",
    "#model_path = gp + \"/cell_movement_v24-no-persistent.xml\"  # for simulation without persistent random walk\n",
    "#model_path = gp + \"/cell_movement_v24-no-persistent-no-pillars.xml\"  # for simulation without persistent random walk and without pillars\n",
    "# defining the summary statistics function\n",
    "max_sequence_length = 120\n",
    "min_sequence_length = 0\n",
    "only_longest_traj_per_cell = True  # mainly to keep the data batchable\n",
    "cells_in_population = 50\n",
    "\n",
    "\n",
    "def make_sumstat_dict(data: Union[dict, np.ndarray]) -> dict:\n",
    "    if isinstance(data, dict):\n",
    "        # get key\n",
    "        key = list(data.keys())[0]\n",
    "        data = data[key]\n",
    "    data = data[0]  # only one sample\n",
    "    # compute the summary statistics\n",
    "    summary_stats_dict = reduced_coordinates_to_sumstat(data)\n",
    "    (ad_mean, _, msd_mean, _, ta_mean, _, vel_mean, _, wt_mean, _) = compute_mean_summary_stats([summary_stats_dict], remove_nan=False)\n",
    "    cleaned_dict = {\n",
    "        'ad': np.array(ad_mean).flatten(),\n",
    "        'msd': np.array(msd_mean).flatten(),\n",
    "        'ta': np.array(ta_mean).flatten(),\n",
    "        'vel': np.array(vel_mean).flatten(),\n",
    "        'wt': np.array(wt_mean).flatten()\n",
    "    }\n",
    "    return cleaned_dict\n",
    "\n",
    "\n",
    "def prepare_sumstats(output_morpheus_model) -> dict:\n",
    "    sim_coordinates = reduce_to_coordinates(output_morpheus_model, \n",
    "                          minimal_length=min_sequence_length, \n",
    "                          maximal_length=max_sequence_length,\n",
    "                          only_longest_traj_per_cell=only_longest_traj_per_cell\n",
    "                          )\n",
    "    \n",
    "    # we now do exactly the same as in the BayesFlow workflow, but here we get only one sample at a time\n",
    "    data_transformed = np.ones((1, cells_in_population, max_sequence_length, 2)) * np.nan\n",
    "    # each cell is of different length, each with x and y coordinates, make a tensor out of it\n",
    "    n_cells_not_visible = 0\n",
    "    if len(sim_coordinates) != 0:\n",
    "        # some cells were visible in the simulation\n",
    "        for c_id, cell_sim in enumerate(sim_coordinates):\n",
    "            # pre-pad the data with zeros, but first write zeros as nans to compute the mean and std\n",
    "            data_transformed[0, c_id, -len(cell_sim['x']):, 0] = cell_sim['x']\n",
    "            data_transformed[0, c_id, -len(cell_sim['y']):, 1] = cell_sim['y']\n",
    "    \n",
    "    return {'sim': data_transformed}\n",
    "\n",
    "\n",
    "sumstat = SummaryStatistics(sum_stat_calculator=prepare_sumstats)                    \n",
    "\n",
    "if on_cluster:\n",
    "    # define the model object\n",
    "    model = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        executable=\"ulimit -s unlimited; /home/jarruda_hpc/CellMigration/morpheus-2.3.7\",\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)\n",
    "\n",
    "    # todo: remember also change tiff path in model.xml!\n",
    "else:\n",
    "    # define the model object\n",
    "    model = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)\n",
    "\n",
    "# parameter values used to generate the synthetic data\n",
    "obs_pars = {\n",
    "    'gradient_strength': 100.,  # strength of the gradient of chemotaxis\n",
    "    'move.strength': 10.,  # strength of directed motion\n",
    "    'move.duration.mean': 0.1,  # mean of exponential distribution (seconds)\n",
    "    'cell_nodes_real': 50.,  # volume of the cell (\\mu m^2)\n",
    "}\n",
    "\n",
    "\n",
    "obs_pars_log = {key: np.log10(val) for key, val in obs_pars.items()}\n",
    "limits = {'gradient_strength': (1, 10000), #(10 ** 4, 10 ** 8),\n",
    "          'move.strength': (1, 100),\n",
    "          'move.duration.mean': (1e-4, 30), #(math.log10((10 ** -2) * 30), math.log10((10 ** 4))), # smallest time step in simulation 5\n",
    "          'cell_nodes_real': (1, 300)}\n",
    "limits_log = {key: (np.log10(val[0]), np.log10(val[1])) for key, val in limits.items()}\n",
    "\n",
    "\n",
    "prior = pyabc.Distribution(**{key: pyabc.RV(\"uniform\", loc=lb, scale=ub-lb)\n",
    "                              for key, (lb, ub) in limits_log.items()})\n",
    "param_names = list(obs_pars.keys())\n",
    "log_param_names = [f'log_{p}' for p in param_names]\n",
    "print(obs_pars)\n",
    "print(limits_log)"
   ],
   "id": "74390dfb0e802a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sigma0 = 550\n",
    "space_x0 = 1173/2\n",
    "space_y0 = 1500/1.31/2\n",
    "x0, y0 = 1173/2, (1500+1500/2+270)/1.31\n",
    "u1 = lambda space_x, space_y: 7/(2*np.pi*(sigma0**2)) *np.exp(-1/2*(((space_x)-(x0))**2+ ((space_y)-(y0))**2)/(sigma0**2))\n",
    "\n",
    "# plot the function\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x = np.linspace(0, 1173 , 100)\n",
    "y = np.linspace(0, 2500 , 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = u1(X, Y)\n",
    "ax.plot_surface(X, Y, Z, alpha=0.5)\n",
    "# plot start points\n",
    "ax.scatter(space_x0, space_y0, u1(space_x0, space_y0), color='r', s=100)\n",
    "\n",
    "ax.set_xlabel('space_x')\n",
    "ax.set_ylabel('space_y')\n",
    "plt.show()\n",
    "\n",
    "space_x0, space_y0, u1(space_x0, space_y0), u1(x0, y0)"
   ],
   "id": "be4eaa8d21c3bfff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if load_synthetic_data:\n",
    "    # simulate test data\n",
    "    test_params = np.array(list(obs_pars_log.values()))\n",
    "    if not os.path.exists(os.path.join(gp, 'test_sim.npy')):\n",
    "        raise FileNotFoundError('Test data not found')\n",
    "    else:\n",
    "        test_sim = np.load(os.path.join(gp, 'test_sim.npy'))\n",
    "        \n",
    "    results_path = 'abc_results'\n",
    "else:\n",
    "    # load real data\n",
    "    from load_data import load_real_data\n",
    "    test_params = None\n",
    "    real_data, real_data_full = load_real_data(data_id=1, \n",
    "                                               max_sequence_length=max_sequence_length, \n",
    "                                               cells_in_population=cells_in_population)\n",
    "    factor = 1.31  # convert from Morpheus to real coordinates in micrometers\n",
    "    real_data = real_data * factor  # when loading the data, it is converted to Morpheus coordinates for ABC\n",
    "    real_data_full = real_data_full * factor  # when loading the data, it is converted to Morpheus coordinates for ABC\n",
    "\n",
    "\n",
    "    test_sim = np.array([real_data[start:start+cells_in_population] for start in range(0, len(real_data), cells_in_population)])[0][np.newaxis]\n",
    "    results_path = 'abc_results_real'\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True,\n",
    "                       tight_layout=True, figsize=(4, 3))\n",
    "    plt.plot(real_data_full[0, :, 0], real_data_full[0, :, 1], color='blue', alpha=0.7)\n",
    "    for cell_id in range(1, real_data_full.shape[0]):\n",
    "        plt.plot(real_data_full[cell_id, :, 0], real_data_full[cell_id, :, 1], linewidth=0.5, color='blue', alpha=0.7)\n",
    "        plt.scatter(real_data_full[cell_id, :, 0], real_data_full[cell_id, :, 1], s=1, color='blue', alpha=0.7)\n",
    "\n",
    "    plt.ylabel('$y$ Position (in $\\mu m$)')\n",
    "    plt.xlabel('$x$ Position (in $\\mu m$)')\n",
    "    #plt.savefig(os.path.join(gp, f'{results_path}/real_data.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "test_sim.shape"
   ],
   "id": "dc31691dc1bbede7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load bayesflow posterior samples\n",
    "if load_synthetic_data:\n",
    "    bayesflow_posterior_samples = np.load(f'amortizer-cell-migration-attention-8-manual/posterior_samples_synthetic.npy')\n",
    "    posterior_sim_abc = np.load(os.path.join(gp, f'{results_path}/posterior_sim_abc.npy'))\n",
    "else:\n",
    "    bayesflow_posterior_samples = np.load(f'amortizer-cell-migration-attention-8-manual/posterior_samples_real.npy')\n",
    "    #bayesflow_posterior_samples = np.load(f'amortizer-cell-migration-ensemble/posterior_samples_real.npy')\n",
    "    #bayesflow_posterior_samples = np.load(f'amortizer-cell-migration-attention-8-manual-include-real/posterior_samples_real.npy')\n",
    "    #bayesflow_posterior_samples = np.load(f'amortizer-cell-migration-attention-8-manual-compare-real/posterior_samples_real.npy')\n",
    "    posterior_sim_abc = None\n",
    "bayesflow_median = np.median(bayesflow_posterior_samples, axis=0)"
   ],
   "id": "999f3d3cf18465fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prior_draws = np.array([list(prior.rvs().values()) for _ in range(1000)])",
   "id": "41ac247d925dab29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ABC with Wasserstein distance",
   "id": "1aff15f15d184db8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def obj_func_wass(sim: dict, obs: dict, return_marginal: bool = False, normalize: bool = False):\n",
    "    total = np.zeros(len(sim.keys()))\n",
    "    for k_i, key in enumerate(sim):\n",
    "        x, y = np.array(sim[key]), np.array(obs[key])\n",
    "        if x.size == 0 or y.size == 0:\n",
    "            return np.inf\n",
    "        total[k_i] = stats.wasserstein_distance(x, y)\n",
    "        if normalize:\n",
    "            max_x = max(np.max(x), 1e-4)  # not y, to use the test data as reference\n",
    "            total[k_i] = total[k_i] / max_x\n",
    "    if return_marginal:\n",
    "        return total\n",
    "    return total.sum()"
   ],
   "id": "1145158513a20ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "abc_posterior_samples = None\n",
    "#redis_sampler = RedisEvalParallelSampler(host=args.ip, port=args.port,\n",
    "#                                         adapt_look_ahead_proposal=False,\n",
    "#                                         look_ahead=False)\n",
    "\n",
    "abc = pyabc.ABCSMC(model, prior,\n",
    "                   distance_function=obj_func_wass,\n",
    "                   summary_statistics=make_sumstat_dict,\n",
    "                   population_size=population_size,\n",
    "                   sampler=pyabc.sampler.MulticoreEvalParallelSampler(n_procs=n_procs)\n",
    "                   #sampler=redis_sampler\n",
    "                   )\n",
    "\n",
    "db_path = os.path.join(gp, f\"{results_path}/{'synthetic' if load_synthetic_data else 'real'}_test_old_sumstats.db\")\n",
    "if not os.path.exists(db_path) and load_synthetic_data:  # not done for real data\n",
    "    history = abc.new(\"sqlite:///\" + db_path, make_sumstat_dict(test_sim))\n",
    "\n",
    "    # start the abc fitting\n",
    "    abc.run(min_acceptance_rate=1e-2, max_nr_populations=15)\n",
    "    print('Done!')\n",
    "elif load_synthetic_data:\n",
    "    history = abc.load(\"sqlite:///\" + db_path)\n",
    "else:\n",
    "    history = None"
   ],
   "id": "1636e7efc136f2e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, len(param_names), tight_layout=True, figsize=(12, 4))\n",
    "for i, param in enumerate(param_names):\n",
    "    for t in range(history.max_t + 1):\n",
    "        df, w = history.get_distribution(m=0, t=t)\n",
    "        pyabc.visualization.plot_kde_1d(\n",
    "            df,\n",
    "            w,\n",
    "            xmin=limits_log[param][0],\n",
    "            xmax=limits_log[param][1],\n",
    "            x=param,\n",
    "            xname=log_param_names[i],\n",
    "            ax=ax[i],\n",
    "            label=f\"PDF t={t}\",\n",
    "        )\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlim((limits_log[param][0]-0.2, limits_log[param][1]+0.2))\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_population_kdes.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, arr_ax = plt.subplots(1, 4, figsize=(12, 3), tight_layout=True)\n",
    "arr_ax = arr_ax.flatten()\n",
    "pyabc.visualization.plot_sample_numbers(history, ax=arr_ax[0])\n",
    "arr_ax[0].get_legend().remove()\n",
    "#pyabc.visualization.plot_walltime(history, ax=arr_ax[1], unit='h')\n",
    "pyabc.visualization.plot_epsilons(history, ax=arr_ax[1])\n",
    "pyabc.visualization.plot_effective_sample_sizes(history, ax=arr_ax[2])\n",
    "pyabc.visualization.plot_acceptance_rates_trajectory(history, ax=arr_ax[3])\n",
    "# remove last axis\n",
    "#arr_ax[-1].axis('off')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_diagnostics.png'))\n",
    "plt.show()\n",
    "\n",
    "pyabc.visualization.plot_credible_intervals(history, levels=[0.95]);"
   ],
   "id": "efcbb86db464a88d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "abc_df, abc_w = history.get_distribution()\n",
    "abc_posterior_samples = pyabc.resample(abc_df[param_names].values, abc_w, n=1000)\n",
    "abc_median = np.median(abc_posterior_samples, axis=0)"
   ],
   "id": "3367ada60af6a8fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plot_posterior_2d(posterior_draws=abc_posterior_samples,\n",
    "                        prior_draws=prior_draws,\n",
    "                        param_names=log_param_names,\n",
    "                        true_params=test_params,\n",
    "                        height=2.5)\n",
    "plt.show()"
   ],
   "id": "98dbfbc06679152c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "fig = plot_posterior_2d(posterior_draws=bayesflow_posterior_samples,\n",
    "                        prior_draws=abc_posterior_samples[:bayesflow_posterior_samples.shape[0]],\n",
    "                        param_names=log_param_names,\n",
    "                        true_params=test_params,\n",
    "                        height=2.5)\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_posterior_abc_vs_posterior_bayesflow.png'))\n",
    "plt.show()"
   ],
   "id": "502d2f44a43d3397"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "distances_df = history.get_weighted_distances()\n",
    "\n",
    "plt.hist(distances_df['distance'])\n",
    "plt.xlabel('Aggregated Wasserstein Distance')\n",
    "plt.show()"
   ],
   "id": "b4a2922f751ccb8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the summary statistics\n",
    "plot_compare_summary_stats(test_sim, posterior_sim_abc); # path=f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_Summary Stats');"
   ],
   "id": "dc4ea826fa0f51e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# plot the trajectory\n",
    "plot_trajectory(test_sim[0], posterior_sim_abc[0], show_umap=True)\n",
    "plot_autocorrelation(test_sim[0], posterior_sim_abc[0])"
   ],
   "id": "757106422ad1d268"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ABC with neural network summary statistics",
   "id": "f49133c6019cdb49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if os.path.exists(os.path.join(gp, 'validation_data.pickle')):\n",
    "    with open(os.path.join(gp, 'validation_data.pickle'), 'rb') as f:\n",
    "        valid_data = pickle.load(f)\n",
    "else:\n",
    "    raise FileNotFoundError('Validation data not found')\n",
    "\n",
    "x_mean = np.nanmean(valid_data['sim_data'], axis=(0, 1, 2))\n",
    "x_std = np.nanstd(valid_data['sim_data'], axis=(0, 1, 2))\n",
    "p_mean = np.mean(valid_data['prior_draws'], axis=0)\n",
    "p_std = np.std(valid_data['prior_draws'], axis=0)\n",
    "print('Mean and std of data:', x_mean, x_std)\n",
    "print('Mean and std of parameters:', p_mean, p_std)\n",
    "\n",
    "\n",
    "# compute the mean of the summary statistics\n",
    "summary_stats_list_ = [reduced_coordinates_to_sumstat(t) for t in valid_data['sim_data']]\n",
    "(_, ad_averg, _, MSD_averg, _, TA_averg, _, VEL_averg, _, WT_averg) = compute_mean_summary_stats(summary_stats_list_, remove_nan=False)\n",
    "\n",
    "direct_conditions_ = np.stack([ad_averg, MSD_averg, TA_averg, VEL_averg, WT_averg]).T\n",
    "# replace inf with -1\n",
    "direct_conditions_[np.isinf(direct_conditions_)] = np.nan\n",
    "        \n",
    "summary_valid_max = np.nanmax(direct_conditions_, axis=0)\n",
    "summary_valid_min = np.nanmin(direct_conditions_, axis=0)"
   ],
   "id": "df1829ce49462436",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use trained neural net as summary statistics\n",
    "def make_sumstat_dict_nn(\n",
    "        data: Union[dict, np.ndarray],\n",
    ") -> dict:\n",
    "    if isinstance(data, dict):\n",
    "        # get key\n",
    "        key = list(data.keys())[0]\n",
    "        data = data[key]\n",
    "\n",
    "    trainer, map_idx_sim = load_model(\n",
    "        model_id=5,\n",
    "        x_mean=x_mean,\n",
    "        x_std=x_std,\n",
    "        p_mean=p_mean,\n",
    "        p_std=p_std,\n",
    "        summary_valid_max=summary_valid_max,\n",
    "        summary_valid_min=summary_valid_min,\n",
    "    )\n",
    "\n",
    "    # configures the input for the network\n",
    "    config_input = trainer.configurator({\"sim_data\": data})\n",
    "    # get the summary statistics\n",
    "    out_dict = {\n",
    "        'summary_net': trainer.amortizer.summary_net(config_input['summary_conditions']).numpy().flatten()\n",
    "    }\n",
    "    # if direct conditions are available, concatenate them\n",
    "    if 'direct_conditions' in config_input.keys():\n",
    "        out_dict['direct_conditions'] = config_input['direct_conditions'].flatten()\n",
    "        \n",
    "    del trainer\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "if on_cluster:\n",
    "    # define the model object\n",
    "    model_nn = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        executable=\"ulimit -s unlimited; /home/jarruda_hpc/CellMigration/morpheus-2.3.7\",\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)\n",
    "\n",
    "    # todo: remember also change tiff path in model.xml!\n",
    "else:\n",
    "    # define the model object\n",
    "    model_nn = morpheus_model.MorpheusModel(\n",
    "        model_path, par_map=par_map, par_scale=\"log10\",\n",
    "        show_stdout=False, show_stderr=False,\n",
    "        clean_simulation=True,\n",
    "        raise_on_error=False, sumstat=sumstat)"
   ],
   "id": "a7c0835963566e42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "synthetic_data_test_nn = make_sumstat_dict_nn(test_sim)\n",
    "synthetic_data_test_nn"
   ],
   "id": "e2e73120c64aa514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#redis_sampler = RedisEvalParallelSampler(host=args.ip, port=args.port,\n",
    "#                                         adapt_look_ahead_proposal=False,\n",
    "#                                         look_ahead=False)\n",
    "\n",
    "abc_nn = pyabc.ABCSMC(model_nn, prior, # here we use now the Euclidean distance, Wasserstein distance is not possible\n",
    "                      population_size=population_size,\n",
    "                      summary_statistics=make_sumstat_dict_nn,\n",
    "                      sampler=pyabc.sampler.MulticoreEvalParallelSampler(n_procs=n_procs)\n",
    "                      #sampler=redis_sampler\n",
    "                      )\n",
    "\n",
    "db_path = os.path.join(gp, f\"{results_path}/{'synthetic' if load_synthetic_data else 'real'}_test_nn_sumstats.db\")\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    history_nn = abc_nn.new(\"sqlite:///\" + db_path, make_sumstat_dict_nn(test_sim))\n",
    "\n",
    "    # start the abc fitting\n",
    "    abc_nn.run(min_acceptance_rate=1e-2, max_nr_populations=15)\n",
    "    print('Done!')\n",
    "else:\n",
    "    history_nn = abc_nn.load(\"sqlite:///\" + db_path)"
   ],
   "id": "8522eceb33f5a581",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, len(param_names), tight_layout=True, figsize=(12, 4))\n",
    "for i, param in enumerate(param_names):\n",
    "    for t in range(history_nn.max_t + 1):\n",
    "        df, w = history_nn.get_distribution(m=0, t=t)\n",
    "        pyabc.visualization.plot_kde_1d(\n",
    "            df,\n",
    "            w,\n",
    "            xmin=limits_log[param][0],\n",
    "            xmax=limits_log[param][1],\n",
    "            x=param,\n",
    "            xname=log_param_names[i],\n",
    "            ax=ax[i],\n",
    "            label=f\"PDF t={t}\",\n",
    "        )\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlim((limits_log[param][0]-0.2, limits_log[param][1]+0.2))\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_population_kdes_nn.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, arr_ax = plt.subplots(1, 4, figsize=(12, 3), tight_layout=True)\n",
    "arr_ax = arr_ax.flatten()\n",
    "pyabc.visualization.plot_sample_numbers(history_nn, ax=arr_ax[0])\n",
    "arr_ax[0].get_legend().remove()\n",
    "#pyabc.visualization.plot_walltime(history_nn, ax=arr_ax[1], unit='h')\n",
    "pyabc.visualization.plot_epsilons(history_nn, ax=arr_ax[1])\n",
    "pyabc.visualization.plot_effective_sample_sizes(history_nn, ax=arr_ax[2])\n",
    "pyabc.visualization.plot_acceptance_rates_trajectory(history_nn, ax=arr_ax[3])\n",
    "# remove last axis\n",
    "#arr_ax[-1].axis('off')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_diagnostics_nn.png'))\n",
    "plt.show()\n",
    "\n",
    "pyabc.visualization.plot_credible_intervals(history_nn, levels=[0.95]);"
   ],
   "id": "82568acc7945ee86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "abc_df, abc_w = history_nn.get_distribution()\n",
    "abc_posterior_samples_nn = pyabc.resample(abc_df[param_names].values, abc_w, n=1000)\n",
    "abc_nn_median = np.median(abc_posterior_samples_nn, axis=0)"
   ],
   "id": "b7d320f9bb9b7e8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, ps in enumerate([abc_posterior_samples, abc_posterior_samples_nn, bayesflow_posterior_samples]):\n",
    "    if ps is None:\n",
    "        continue\n",
    "    fig = plot_posterior_2d(\n",
    "        posterior_draws=ps,\n",
    "        prior_draws=prior_draws,\n",
    "        param_names=log_param_names,\n",
    "        true_params=test_params,\n",
    "        post_color=['#9AB8D7', '#EEBC88', '#A7CE97'][i],\n",
    "        post_alpha=1,\n",
    "        bins='auto',\n",
    "        height=2.5\n",
    "    )\n",
    "    plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_posterior_vs_prior_{i}.png'))\n",
    "    plt.show()"
   ],
   "id": "e22bad1cd301167d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if abc_posterior_samples is not None:\n",
    "    #colors = ['#e66101', '#5e3c99', '#fdb863', '#b2abd2']\n",
    "\n",
    "    # Compute means and standard deviations\n",
    "    prior_mean = np.mean(prior_draws, axis=0)\n",
    "    posterior_mean_abc = np.mean(abc_posterior_samples, axis=0)\n",
    "    posterior_mean_abc_nn = np.mean(abc_posterior_samples_nn, axis=0)\n",
    "    posterior_mean_bf = np.mean(bayesflow_posterior_samples, axis=0)\n",
    "\n",
    "    prior_std = np.std(prior_draws, axis=0)\n",
    "    posterior_std_abc = np.std(abc_posterior_samples, axis=0)\n",
    "    posterior_std_abc_nn = np.std(abc_posterior_samples_nn, axis=0)\n",
    "    posterior_std_bf = np.std(bayesflow_posterior_samples, axis=0)\n",
    "\n",
    "    # Calculate z-scores and contractions\n",
    "    z_scores = [(p_mean - prior_mean) / prior_std for p_mean in\n",
    "                [posterior_mean_abc, posterior_mean_abc_nn, posterior_mean_bf]]\n",
    "    contractions = [1 - (p_std / prior_std) for p_std in\n",
    "                [posterior_std_abc, posterior_std_abc_nn, posterior_std_bf]]\n",
    "\n",
    "    # Plotting Z-scores and contractions for both methods\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4), tight_layout=True)\n",
    "\n",
    "    # Z-Scores for both methods\n",
    "    for i, z in enumerate(z_scores):\n",
    "        ax1.bar(np.arange(len(param_names)) + 0.25 * i, z, width=0.2, alpha=0.5, align='center',\n",
    "                label=['ABC Hand-Crafted Summaries', 'ABC Learned Summaries', 'NPE Learned Summaries'][i])\n",
    "    #ax1.set_xlabel('Parameter')\n",
    "    ax1.set_ylabel('Z-Score')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(np.arange(len(param_names)) + 0.2)\n",
    "    ax1.set_xticklabels(log_param_names)\n",
    "    ax1.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "    # Plot Contractions for both methods on secondary axis\n",
    "    ax2 = ax1.twinx()\n",
    "    for i, c in enumerate(contractions):\n",
    "        ax2.plot(np.arange(0.2, len(param_names)), c, alpha=0.5, marker='o', linestyle='--')\n",
    "    ax2.set_ylabel('--●--  Contraction')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "    #handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "    fig.legend(handles1, labels1,\n",
    "               loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "    #fig.suptitle(f'Comparison of Z-Scores and Contraction')\n",
    "    fig.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_z_scores_contraction.png'), bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "fb7c8bdd7244f0a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ordering = [0,4,1,5,2,6,3,7]\n",
    "if abc_posterior_samples is not None:\n",
    "    ordering = np.concatenate([[i,i+4, i+8] for i in range(4)])\n",
    "    all_params = np.concatenate((abc_posterior_samples,\n",
    "                                 abc_posterior_samples_nn,\n",
    "                                 bayesflow_posterior_samples), axis=-1)\n",
    "    log_param_names_plot = np.array(\n",
    "        [f'ABC' for n in log_param_names] + [f'{n} $\\quad$ ABC_NN' for n in log_param_names] + [f'NPE' for n in log_param_names]\n",
    "    )[ordering]\n",
    "    param_names_plot = np.array(\n",
    "        [f'ABC' for n in param_names] + [f'{n} $\\quad$ ABC_NN' for n in param_names] + [f'NPE' for n in param_names]\n",
    "    )[ordering]\n",
    "    color_list = ['#9AB8D7', '#EEBC88', '#A7CE97']*len(param_names)\n",
    "else:\n",
    "    ordering = np.concatenate([[i,i+4] for i in range(4)])\n",
    "    all_params = np.concatenate((abc_posterior_samples_nn,\n",
    "                                 bayesflow_posterior_samples), axis=-1)\n",
    "    log_param_names_plot = np.array(\n",
    "        [f'{n} $\\quad$ ABC_NN' for n in log_param_names] + [f'NPE' for n in log_param_names]\n",
    "    )[ordering]\n",
    "    param_names_plot = np.array(\n",
    "        [f'{n} $\\quad$ ABC_NN' for n in param_names] + [f'NPE' for n in param_names]\n",
    "    )[ordering]\n",
    "    color_list = ['#EEBC88', '#A7CE97']*len(param_names)\n",
    "\n",
    "ax = sampling_parameter_cis(\n",
    "    all_params[:, ordering],\n",
    "    true_param=np.concatenate((test_params, test_params, test_params))[ordering] if test_params is not None else None,\n",
    "    param_names=log_param_names_plot,\n",
    "    alpha=[95, 90 , 80],\n",
    "    color_list=color_list,\n",
    "    show_median=False if test_params is not None else True,\n",
    "    size=(7, 4),\n",
    "    legend_bbox_to_anchor=(0.45,1)\n",
    ")\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_posterior_credible_intervals_log.png'))\n",
    "plt.show()\n",
    "\n",
    "all_params = np.power(10, all_params)\n",
    "ax = sampling_parameter_cis(\n",
    "    all_params[:, ordering],\n",
    "    true_param=np.power(10, np.concatenate((test_params, test_params, test_params))[ordering]) if test_params is not None else None,\n",
    "    param_names=param_names_plot,\n",
    "    alpha=[95, 90 , 80],\n",
    "    color_list=color_list,\n",
    "    show_median=False if test_params is not None else True,\n",
    "    size=(7, 4),\n",
    "    legend_bbox_to_anchor=(0.99,0.35)\n",
    ")\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_posterior_credible_intervals.png'))\n",
    "plt.show()"
   ],
   "id": "c851aaf76d152b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_samples = np.concatenate([\n",
    "    prior_draws[:bayesflow_posterior_samples.shape[0]],\n",
    "    abc_posterior_samples_nn[:bayesflow_posterior_samples.shape[0]],\n",
    "    bayesflow_posterior_samples\n",
    "])\n",
    "color_code = np.concatenate([\n",
    "    np.zeros(prior_draws[:bayesflow_posterior_samples.shape[0]].shape[0]), \n",
    "    np.ones(abc_posterior_samples_nn[:bayesflow_posterior_samples.shape[0]].shape[0]),\n",
    "    np.ones(bayesflow_posterior_samples.shape[0])*2\n",
    "])\n",
    "\n",
    "# make a umap plot\n",
    "import umap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1)\n",
    "embedding = reducer.fit_transform(all_samples)\n",
    "\n",
    "plt.figure(tight_layout=True, figsize=(5, 5))\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[colors[int(i)] for i in color_code],\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "patches = [Patch(color=colors[i], label=f'{[\"Prior\", \"ABC\", \"NPE\"][i]}') for i in range(len(colors))]\n",
    "plt.legend(handles=patches)\n",
    "plt.title('UMAP Posterior Projection')\n",
    "#plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_umap_posterior_comparison.png'))\n",
    "plt.show()"
   ],
   "id": "4033f43895a45b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def wrapper_fun(sample_i):\n",
    "    sim_dict = {key: p for key, p in zip(obs_pars.keys(), abc_posterior_samples_nn[sample_i])}\n",
    "    #sim_dict = {key: p for key, p in zip(obs_pars.keys(), bayesflow_posterior_samples[sample_i])}\n",
    "    posterior_sim = model(sim_dict)\n",
    "    return posterior_sim['sim']\n",
    "\n",
    "from multiprocess import Pool\n",
    "\n",
    "def check_if_done(result):\n",
    "    print(\"Task finished\")\n",
    "\n",
    "with Pool() as pool:\n",
    "    async_results = [pool.apply_async(wrapper_fun, (i,), callback=check_if_done) for i in range(100)]\n",
    "\n",
    "    # Wait for all results to complete\n",
    "    sim_list = [result.get() for result in async_results]\n",
    "\n",
    "posterior_sim_nn = np.concatenate(sim_list)\n",
    "np.save(os.path.join(gp, f'{results_path}/posterior_sim_nn_abc.npy'), posterior_sim_nn)"
   ],
   "id": "c6df8b775ee8afff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # get posterior samples and simulate\n",
    "# if not os.path.exists(os.path.join(gp, f'{results_path}/posterior_sim_nn_bf.npy')):\n",
    "#     # simulate the data\n",
    "#     sim_list = []\n",
    "#     for i in tqdm(range(100)):\n",
    "#         #if i == 0:\n",
    "#         #    sim_dict = {key: p for key, p in zip(obs_pars.keys(), abc_nn_median)}\n",
    "#         #else:\n",
    "#         sim_dict = {key: p for key, p in zip(obs_pars.keys(), abc_posterior_samples_nn[i])}\n",
    "#         posterior_sim = model_nn(sim_dict)\n",
    "#         sim_list.append(posterior_sim['sim'])\n",
    "#     posterior_sim_nn_bf = np.concatenate(sim_list)\n",
    "#     np.save(os.path.join(gp, f'{results_path}/posterior_sim_nn_bf.npy'), posterior_sim_nn_bf)\n",
    "# else:\n",
    "\n",
    "if load_synthetic_data:\n",
    "    posterior_sim_nn_abc = np.load(os.path.join(gp, f'{results_path}/posterior_sim_nn_abc.npy'))\n",
    "    posterior_sim_nn_bf = np.load(os.path.join(gp, f'{results_path}/posterior_sim_nn_bf.npy'))\n",
    "    (posterior_sim_nn_bf_no_pillars,\n",
    "     posterior_sim_nn_bf_no_chemokine, posterior_sim_nn_bf_no_pillars_chemokine,\n",
    "     posterior_sim_nn_bf_no_persistent, posterior_sim_nn_bf_no_pillars_persistent) = None, None, None, None, None\n",
    "else:\n",
    "    posterior_sim_nn_abc = np.load(os.path.join(gp, f'{results_path}/posterior_sim_nn_abc.npy'))\n",
    "    posterior_sim_nn_bf = np.load(os.path.join(gp, f'{results_path}/posterior_sim_nn_bf.npy')) * factor\n",
    "    posterior_sim_nn_bf_no_pillars = np.load(os.path.join(gp, f'{results_path}/posterior_sim_nn_bf_no_pillars.npy')) * factor\n",
    "    posterior_sim_nn_bf_no_chemokine = np.load(os.path.join(gp, f'{results_path}/posterior_sim_bf_no_chemokine.npy')) * factor\n",
    "    posterior_sim_nn_bf_no_pillars_chemokine = np.load(os.path.join(gp, f'{results_path}/posterior_sim_bf_no_pillars_chemokine.npy')) * factor\n",
    "    posterior_sim_nn_bf_no_persistent = np.load(os.path.join(gp, f'{results_path}/posterior_sim_bf_no_persistent.npy')) * factor\n",
    "    posterior_sim_nn_bf_no_pillars_persistent = np.load(os.path.join(gp, f'{results_path}/posterior_sim_bf_no_pillars_persistent.npy')) * factor"
   ],
   "id": "abf701f5976fe37e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if posterior_sim_nn_abc is not None:  # for comparison of abc and npe on synthetic data\n",
    "    sumstats_abc = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_abc]\n",
    "    sumstats_nn_abc = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_abc]\n",
    "    sumstats_bf = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf]\n",
    "\n",
    "    plot_sumstats_distance_hist(obj_func_wass, make_sumstat_dict(test_sim), [sumstats_abc, sumstats_nn_abc, sumstats_bf],\n",
    "                                labels=['ABC Hand-Crafted Summaries', 'ABC Learned Summaries', 'NPE Learned Summaries'],\n",
    "                                path=os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_sumstats_wasserstein_nn.png'))"
   ],
   "id": "3ed4bda8be95a2b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = ['#e66101', '#5e3c99', '#fdb863', '#b2abd2']\n",
    "if posterior_sim_nn_bf_no_pillars_chemokine is not None:\n",
    "    labels = ['Simulation w/ Pillars & w/ Chemokine',\n",
    "          'Simulation w/o Pillars & w/ Chemokine',\n",
    "          'Simulation w/ Pillars & w/o Chemokine',\n",
    "          'Simulation w/o Pillars & w/o Chemokine']\n",
    "\n",
    "    sumstats_bf = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf]\n",
    "    sumstats_bf_p = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_pillars]\n",
    "    sumstats_bf_c = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_chemokine]\n",
    "    sumstats_bf_pc = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_pillars_chemokine]\n",
    "\n",
    "    plot_sumstats_distance_hist(obj_func_wass, make_sumstat_dict(test_sim), [sumstats_bf, sumstats_bf_p, sumstats_bf_c, sumstats_bf_pc],\n",
    "                                    labels=labels,\n",
    "                                    colors=colors,\n",
    "                                    path=os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_sumstats_wasserstein_conditions_chemokine.png')\n",
    "                                    )"
   ],
   "id": "5d2a4f30cec0a987",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if posterior_sim_nn_bf_no_pillars_persistent is not None:\n",
    "    labels = ['Simulation w/ Pillars & w/ Persistence',\n",
    "          'Simulation w/o Pillars & w/ Persistence',\n",
    "          'Simulation w/ Pillars & w/o Persistence',\n",
    "          'Simulation w/o Pillars & w/o Persistence']\n",
    "\n",
    "    sumstats_bf = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf]\n",
    "    sumstats_bf_p = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_pillars]\n",
    "    sumstats_bf_per = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_persistent]\n",
    "    sumstats_bf_pper = [make_sumstat_dict(p_sim[np.newaxis]) for p_sim in posterior_sim_nn_bf_no_pillars_persistent]\n",
    "\n",
    "    plot_sumstats_distance_hist(obj_func_wass, make_sumstat_dict(test_sim), [sumstats_bf, sumstats_bf_p, sumstats_bf_per, sumstats_bf_pper],\n",
    "                                    labels=labels,\n",
    "                                    colors=colors,\n",
    "                                    path=os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_sumstats_wasserstein_conditions_persistence.png')\n",
    "                                )"
   ],
   "id": "63064105b579c378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True,\n",
    "                       tight_layout=True, figsize=(9, 4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "pop_id = 0\n",
    "cell_popiulatinos = [posterior_sim_nn_bf[pop_id], posterior_sim_nn_bf_no_pillars[pop_id],\n",
    "                     posterior_sim_nn_bf_no_chemokine[pop_id], posterior_sim_nn_bf_no_pillars_chemokine[pop_id]]\n",
    "\n",
    "# Add labels to the top and right side\n",
    "ax[1].set_title(' ')  # to have space for the different labels\n",
    "fig.text(0.22, 0.94, 'With Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.66, 0.94, 'Without Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.99, 0.73, 'W/ Chemokine', va='center', rotation=270, fontsize=14) # Right side label\n",
    "fig.text(0.99, 0.325, 'W/o Chemokine', va='center', rotation=270, fontsize=14)\n",
    "\n",
    "for i, cp in enumerate(cell_popiulatinos):\n",
    "    ax[i].plot(cp[0, :, 0], cp[0, :, 1], color=colors[i])\n",
    "    for cell_id in range(1, cells_in_population):\n",
    "        ax[i].plot(cp[cell_id, :, 0], cp[cell_id, :, 1], linewidth=0.5, color=colors[i])\n",
    "        ax[i].scatter(cp[cell_id, :, 0], cp[cell_id, :, 1], s=1, color=colors[i])\n",
    "\n",
    "ax[0].set_ylabel('$y$ Position (in $\\mu m$)')\n",
    "ax[2].set_ylabel('$y$ Position (in $\\mu m$)')\n",
    "ax[2].set_xlabel('$x$ Position (in $\\mu m$)')\n",
    "ax[3].set_xlabel('$x$ Position (in $\\mu m$)')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/simulated_trajectories_chemokine.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "fbc1d5c7086b7a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True,\n",
    "                       tight_layout=True, figsize=(9, 4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "cell_popiulatinos = [posterior_sim_nn_bf[pop_id], posterior_sim_nn_bf_no_pillars[pop_id],\n",
    "                     posterior_sim_nn_bf_no_persistent[pop_id], posterior_sim_nn_bf_no_pillars_persistent[pop_id]]\n",
    "colors = ['#e66101', '#5e3c99', '#fdb863', '#b2abd2']\n",
    "\n",
    "# Add labels to the top and right side\n",
    "ax[1].set_title(' ')  # to have space for the different labels\n",
    "fig.text(0.22, 0.94, 'With Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.66, 0.94, 'Without Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.99, 0.73, 'W/ Persistence', va='center', rotation=270, fontsize=14) # Right side label\n",
    "fig.text(0.99, 0.325, 'W/o Persistence', va='center', rotation=270, fontsize=14)\n",
    "\n",
    "for i, cp in enumerate(cell_popiulatinos):\n",
    "    ax[i].plot(cp[0, :, 0], cp[0, :, 1], color=colors[i])\n",
    "    for cell_id in range(1, cells_in_population):\n",
    "        ax[i].plot(cp[cell_id, :, 0], cp[cell_id, :, 1], linewidth=0.5, color=colors[i])\n",
    "        ax[i].scatter(cp[cell_id, :, 0], cp[cell_id, :, 1], s=1, color=colors[i])\n",
    "\n",
    "ax[0].set_ylabel('$y$ Position (in $\\mu m$)')\n",
    "ax[2].set_ylabel('$y$ Position (in $\\mu m$)')\n",
    "ax[2].set_xlabel('$x$ Position (in $\\mu m$)')\n",
    "ax[3].set_xlabel('$x$ Position (in $\\mu m$)')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/simulated_trajectories_persistence.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "e71734400edfaa53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msd_lags_pc = compute_MSD_lags(posterior_sim_nn_bf_no_pillars_chemokine[pop_id])\n",
    "msd_lags_p = compute_MSD_lags(posterior_sim_nn_bf_no_pillars[pop_id])\n",
    "msd_lags_c = compute_MSD_lags(posterior_sim_nn_bf_no_chemokine[pop_id])\n",
    "msd_lags_per = compute_MSD_lags(posterior_sim_nn_bf_no_persistent[pop_id])\n",
    "msd_lags_pper = compute_MSD_lags(posterior_sim_nn_bf_no_pillars_persistent[pop_id])\n",
    "msd_lags_sim = compute_MSD_lags(posterior_sim_nn_bf[pop_id])\n",
    "\n",
    "# msd_lags_pc = np.concatenate([compute_MSD_lags(ps) for ps in posterior_sim_nn_bf_no_pillars_chemokine])\n",
    "# msd_lags_p = np.concatenate([compute_MSD_lags(ps) for ps in posterior_sim_nn_bf_no_pillars])\n",
    "# msd_lags_c = np.concatenate([compute_MSD_lags(ps) for ps in posterior_sim_nn_bf_no_chemokine])\n",
    "# msd_lags_sim = np.concatenate([compute_MSD_lags(ps) for ps in posterior_sim_nn_bf])\n",
    "\n",
    "msd_lags_real = compute_MSD_lags(test_sim[0])"
   ],
   "id": "de9265e58f24c45d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msd_lags_list = [msd_lags_sim, msd_lags_p, msd_lags_c, msd_lags_pc]\n",
    "labels = ['Simulation w/ Pillars & Chemokine',\n",
    "          'Simulation w/o Pillars & w/ Chemokine',\n",
    "          'Simulation w/ Pillars & w/o Chemokine',\n",
    "          'Simulation w/o Pillars & Chemokine']\n",
    "colors = ['#e66101', '#5e3c99', '#fdb863', '#b2abd2']\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9, 4), tight_layout=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (msd_lags, l) in enumerate(zip(msd_lags_list, labels)):\n",
    "\n",
    "    # Compute valid counts along the axis (non-NaN entries)\n",
    "    valid_counts = np.sum(~np.isnan(msd_lags), axis=0)\n",
    "    mean_msd_test = np.where(valid_counts > 1, np.nanmean(msd_lags, axis=0), np.nan)\n",
    "    yerr_test = np.where(valid_counts > 1, np.nanstd(msd_lags, axis=0), np.nan)\n",
    "\n",
    "    # Clip error bars to avoid negative values for plotted range\n",
    "    lower_bound_test = np.maximum(mean_msd_test - yerr_test, 0)\n",
    "    upper_bound_test = mean_msd_test + yerr_test\n",
    "\n",
    "    ax[i].errorbar(np.arange(1, msd_lags.shape[1] + 1) * 30 / 60,\n",
    "                   mean_msd_test/ 1e6,\n",
    "                   yerr=[(mean_msd_test - lower_bound_test) / 1e6, (upper_bound_test - mean_msd_test) / 1e6],\n",
    "                   capsize=1, elinewidth=0.5, label=l, color=colors[i]\n",
    "                   )\n",
    "ax[1].set_title(' ')  # to have space for the different labels\n",
    "\n",
    "# Add labels to the top and right side\n",
    "fig.text(0.24, 0.94, 'With Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.67, 0.94, 'Without Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.99, 0.73, 'W/ Chemokine', va='center', rotation=270, fontsize=14) # Right side label\n",
    "fig.text(0.99, 0.325, 'W/o Chemokine', va='center', rotation=270, fontsize=14)\n",
    "\n",
    "ax[2].set_ylabel('$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$ Mean Squared Displacement ($mm^2$)\\n$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$(mean and std over cells)')\n",
    "ax[2].set_xlabel('Time Lag (in minutes)')\n",
    "ax[3].set_xlabel('Time Lag (in minutes)')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_msd_lags_chemokine.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "7bfaddbdd0ef06bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msd_lags_list = [msd_lags_sim, msd_lags_p, msd_lags_per, msd_lags_pper]\n",
    "labels = ['Simulation w/ Pillars & Persistence',\n",
    "          'Simulation w/o Pillars & w/ Persistence',\n",
    "          'Simulation w/ Pillars & w/o Persistence',\n",
    "          'Simulation w/o Pillars & Persistence']\n",
    "colors = ['#e66101', '#5e3c99', '#fdb863', '#b2abd2']\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9, 4), tight_layout=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (msd_lags, l) in enumerate(zip(msd_lags_list, labels)):\n",
    "\n",
    "    # Compute valid counts along the axis (non-NaN entries)\n",
    "    valid_counts = np.sum(~np.isnan(msd_lags), axis=0)\n",
    "    mean_msd_test = np.where(valid_counts > 1, np.nanmean(msd_lags, axis=0), np.nan)\n",
    "    yerr_test = np.where(valid_counts > 1, np.nanstd(msd_lags, axis=0), np.nan)\n",
    "\n",
    "    # Clip error bars to avoid negative values for plotted range\n",
    "    lower_bound_test = np.maximum(mean_msd_test - yerr_test, 0)\n",
    "    upper_bound_test = mean_msd_test + yerr_test\n",
    "\n",
    "    ax[i].errorbar(np.arange(1, msd_lags.shape[1] + 1) * 30 / 60,\n",
    "                   mean_msd_test/ 1e6,\n",
    "                   yerr=[(mean_msd_test - lower_bound_test) / 1e6, (upper_bound_test - mean_msd_test) / 1e6],\n",
    "                   capsize=1, elinewidth=0.5, label=l, color=colors[i]\n",
    "                   )\n",
    "ax[1].set_title(' ')  # to have space for the different labels\n",
    "\n",
    "# Add labels to the top and right side\n",
    "fig.text(0.24, 0.94, 'With Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.67, 0.94, 'Without Pillar Forest', va='center', fontsize=14)\n",
    "fig.text(0.99, 0.73, 'W/ Persistence', va='center', rotation=270, fontsize=14) # Right side label\n",
    "fig.text(0.99, 0.325, 'W/o Persistence', va='center', rotation=270, fontsize=14)\n",
    "\n",
    "ax[2].set_ylabel('$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$ Mean Squared Displacement ($mm^2$)\\n$\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad$(mean and std over cells)')\n",
    "ax[2].set_xlabel('Time Lag (in minutes)')\n",
    "ax[3].set_xlabel('Time Lag (in minutes)')\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_msd_lags_persistence.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "98b0344485191b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the summary statistics\n",
    "if posterior_sim_nn_abc is not None:\n",
    "    plot_compare_summary_stats(test_sim, posterior_sim_nn_abc)\n",
    "plot_compare_summary_stats(test_sim, posterior_sim_nn_bf);"
   ],
   "id": "2fc7d0bce16dd4f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# plot the trajectory\n",
    "plot_trajectory(test_sim[0], posterior_sim_nn_abc[0], label_true=None if load_synthetic_data else 'Real Trajectories', two_plots=True, show_umap=True)\n",
    "plot_autocorrelation(test_sim[0], posterior_sim_nn_abc[0])"
   ],
   "id": "eeab4bd87316079c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_trajec = np.concatenate([\n",
    "    test_sim[0],\n",
    "    #posterior_sim_nn_abc[0],\n",
    "    posterior_sim_nn_bf[0],\n",
    "])\n",
    "all_trajec = np.concatenate([all_trajec[..., 0], all_trajec[..., 1]], axis=1)\n",
    "all_trajec[np.isnan(all_trajec)] = -1\n",
    "\n",
    "color_code = np.concatenate([\n",
    "    np.zeros(test_sim[0].shape[0]), \n",
    "    #np.ones(posterior_sim_nn_abc[0].shape[0]),\n",
    "    np.ones(posterior_sim_nn_bf[0].shape[0])*2\n",
    "])\n",
    "\n",
    "# make a umap plot\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1)\n",
    "embedding = reducer.fit_transform(all_trajec)\n",
    "\n",
    "plt.figure(tight_layout=True, figsize=(5, 5))\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[colors[int(i)] for i in color_code],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "#patches = [Patch(color=colors[i], label=f'{[\"Real\", \"ABC\", \"NPE\"][i]}') for i in range(len(colors))]\n",
    "patches = [Patch(color=colors[i], label=f'{[\"Real\", \"ABC\", \"NPE\"][i]}') for i in [0,2]]\n",
    "plt.legend(handles=patches)\n",
    "plt.title('UMAP Trajectory Projection')\n",
    "#plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_umap_trajectory_comparison.png'))\n",
    "plt.savefig(os.path.join(gp, f'{results_path}/{\"synthetic\" if load_synthetic_data else \"real\"}_umap_trajectory.png'))\n",
    "plt.show()"
   ],
   "id": "2988408ddbed2e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_summary_vector(data):\n",
    "    data = make_sumstat_dict_nn(data)\n",
    "    data = np.concatenate([data['summary_net'], data['direct_conditions']])[np.newaxis]\n",
    "    return data"
   ],
   "id": "38d3890023cdcf49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d1 = get_summary_vector(test_sim)\n",
    "d2 = np.concatenate([get_summary_vector(sim[np.newaxis]) for sim in posterior_sim_nn_abc])\n",
    "d3 = np.concatenate([get_summary_vector(sim[np.newaxis]) for sim in posterior_sim_nn_bf])\n",
    "all_latent_trajec = np.concatenate([d1, d2, d3])\n",
    "\n",
    "color_code = np.concatenate([\n",
    "    np.zeros(d1.shape[0]), \n",
    "    np.ones(d2.shape[0]),\n",
    "    np.ones(d3.shape[0])*2\n",
    "])"
   ],
   "id": "c16558b23c3489c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# make a umap plot\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1, metric='manhattan')\n",
    "embedding = reducer.fit_transform(all_latent_trajec)\n",
    "\n",
    "plt.figure(tight_layout=True, figsize=(5, 5))\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[colors[int(i)] for i in color_code],\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "patches = [Patch(color=colors[i], label=f'{[\"Real\", \"ABC\", \"NPE\"][i]}') for i in range(len(colors))]\n",
    "plt.legend(handles=patches)\n",
    "plt.title('UMAP Latent Summary Projection')\n",
    "plt.show()"
   ],
   "id": "82ad123c2605d4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def compute_latent_error(true, pred, p=1):  # p=1 is default in pyABC\n",
    "    true = make_sumstat_dict_nn(true)\n",
    "    true = np.concatenate([true['summary_net'], true['direct_conditions']])\n",
    "    if pred.shape[0] == 1:\n",
    "        pred = make_sumstat_dict_nn(pred)\n",
    "    else:\n",
    "        print('only computing error for first sample')\n",
    "        pred = make_sumstat_dict_nn(pred[0][np.newaxis])    \n",
    "    pred = np.concatenate([pred['summary_net'], pred['direct_conditions']])\n",
    "    \n",
    "    distance = np.abs(true - pred)\n",
    "    print(distance)\n",
    "    distance = (distance**p).sum() ** (1 / p)\n",
    "    return distance"
   ],
   "id": "3255447f8012048f"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "compute_latent_error(test_sim, posterior_sim_nn_abc), compute_latent_error(test_sim, posterior_sim_nn_bf)",
   "id": "d1a0e5689cd0d3bb"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "plt.hist([compute_latent_error(test_sim, posterior_sim_nn_abc[i][np.newaxis])\n",
    "          for i in range(posterior_sim_nn_abc.shape[0])],\n",
    "         alpha=0.5, label='ABC', bins=10, density=True)\n",
    "plt.hist([compute_latent_error(test_sim, posterior_sim_nn_bf[i][np.newaxis])\n",
    "          for i in range(posterior_sim_nn_bf.shape[0])],\n",
    "         alpha=0.5, label='NPE', bins=10, density=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "84e35ddfc1bc4ca5"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "compute_latent_error(posterior_sim_nn_abc[0][np.newaxis], posterior_sim_nn_bf[0][np.newaxis])",
   "id": "fdb2c4997fedb7a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "640bc91798726ee6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
